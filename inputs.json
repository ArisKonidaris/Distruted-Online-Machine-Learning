{
	
	"simulations":{
		"encoding" : "UTF-8",
		"net_name_1" : "net1",
		"net_name_2" : "net2",
		"number_of_networks" : 1,
		"learning_problem" : "classification",
		"negative_labels" : true,
		"data" : "tests_hdf5_Data",
		"seed" : -1 //Give any non negative value for random reproducibility
					//and any negative value for "completely random results".
	},
	
	"tests_hdf5_Data":{
		"encoding" : "UTF-8",
		"batch_size" : 50,
		"warmup_size" : 500,
		"test_size" : 0.2
	},
	
	"tests_Generated_Data":{
		"encoding" : "UTF-8",
		"linearly_seperable" : true,
		"batch_size" : 1,
		"warmup_size" : 50,
		"number_of_features" : 100,
		"test_size" : 100000
	},
	
	"gm_network_net1":{ // format : gm_network_<network_name>
		"encoding" : "UTF-8",
		"number_of_local_nodes" : 4,
		"learning_algorithm" : "MLP", // Learning algorithm options : [PA, Kernel_PA, MLP, PA_Reg, NN_Reg]
		"parameters_of_learner" : "NN_Classifier",
		"distributed_learning_algorithm" : "dist_algo_net3"
	},
	
	"gm_network_net2":{ // format : gm_network_<network name>
		"encoding" : "UTF-8",
		"number_of_local_nodes" : 4,
		"learning_algorithm" : "PA", // Learning algorithm options : [PA, Kernel_PA, MLP, PA_Reg, NN_Reg]
		"parameters_of_learner" : "Parameters_Passive_Aggressive_Classifier", //NN_Classifier
		"distributed_learning_algorithm" : "dist_algo_net2"
	},
	
	"gm_network_net3":{ // format : gm_network_<network name>
		"encoding" : "UTF-8",
		"number_of_local_nodes" : 4,
		"learning_algorithm" : "MLP", // Learning algorithm options : [PA, Kernel_PA, MLP, PA_Reg, NN_Reg]
		"parameters_of_learner" : "NN_Classifier", //NN_Classifier
		"distributed_learning_algorithm" : "dist_algo_net2"
	},
	
	"dist_algo_net1":{
		"algorithm" : "Batch_Learning",
		"batch_size" : 30
	},
	
	"dist_algo_net2":{
		"algorithm" : "Michael_Kamp",
		"threshold" : 0.000008,
		"batch_size" : 128
	},
	
	// This is for neural networks.
	"dist_algo_net3":{
		"algorithm" : "Michael_Kamp",
		"threshold" : 0.08,
		"batch_size" : 300
	},
	
	"parameters" : {
		"encoding" : "UTF-8",
		"regularization" : "l2", // The regularization method. ('none', 'l1', 'l2')
		"C" : 1e-6, // Regularization/Aggressiveness parameter for training. Default: 0.01
		//"test_size" : 0.1, // Size of test dataset.
		"test_size" : 10000, // Size of test dataset.
		"epochs" : 1, // Number of passes over the data.
		"negative_labels" : true, // Set the y=0 labels to -1.
		"kernel" : "poly", // The kernel to be used by the learner.
		"degree" : 3, // The degree of the polynomial kernel. [optional] default : 2.
		"offset" : 0.0, // The offset of the polynomial kernel. [optional] default : 0.0.
		"sigma" : 1.0, // The sigma parameter of the gaussian kernel. [optional] default 1.0. 
		"a" : 0.5, // Sparce Passive Aggressive parameter a.
		"b" : 40, // Sparce Passive Aggressive parameter b.
		"maxSVs" : 2000, // Maximum number of support vectors.
		"epsilon" : 1e-5 // Regression loss incensitivity 
    },
	
	"data" : {
		"encoding" : "UTF-8",
		"file_name" : "TestFile2.h5", // The name of the hdf5 file.
		//"dataset_name" : "Linear5000", // The name of the dataset in the hdf5 file.
		//"dataset_name" : "Linear600000", // The name of the dataset in the hdf5 file.
		"dataset_name" : "Linear1000000" // The name of the dataset in the hdf5 file.
		//"dataset_name" : "LinearReg1000000", // The name of the dataset in the hdf5 file.
		//"dataset_name" : "SUSY_dataset", // The SUSY dataset from the UCI Machine Learning Repository
		//"dataset_name" : "SUSY", // The SUSY dataset from the UCI Machine Learning Repository
		//"train_dset_name" : "AMNIST_train",
		//"test_dset_name" : "MNIST_test"
	},
	
	"data_classificaton" : {
		"encoding" : "UTF-8",
		"file_name" : "TestFile2.h5", // The name of the hdf5 file.
		"dataset_name" : "Linear1000000", // The name of the dataset in the hdf5 file.
		"predictions_file_name" : "PA_II_Predictions.csv", // File to save the predictions.
		"model_file_name" : "PA_II_Model.csv" // File to save the model.
	},
	
	"data_regression" : {
		"encoding" : "UTF-8",
		"file_name" : "TestFile2.h5", // The name of the hdf5 file.
		"dataset_name" : "LinearReg1000000", // The name of the dataset in the hdf5 file.
		"predictions_file_name" : "PA_II_Predictions.csv", // File to save the predictions.
		"model_file_name" : "PA_II_Model.csv" // File to save the model.
	},

	"Parameters_Passive_Aggressive_Classifier" : {
		"encoding" : "UTF-8",
		"regularization" : "l2", // The regularization method. ('none', 'l1', 'l2')
		"C" : 1e-6 // Regularization/Aggressiveness parameter for training. Default: 0.01
    },
	
	"Parameters_Kernel_Passive_Aggressive_Classifier" : {
		"encoding" : "UTF-8",
		"regularization" : "l2", // The regularization method. ('none', 'l1', 'l2')
		"C" : 1e-6, // Regularization/Aggressiveness parameter for training. Default: 0.01
		"test_size" : 0.1, // Size of test dataset.
		"epochs" : 200, // Number of passes over the data.
		"negative_labels" : true, // Set the y=0 labels to -1.
		"kernel" : "poly", // The kernel to be used by the learner.
		"degree" : 3, // The degree of the polynomial kernel. [optional] default : 2.
		"offset" : 0.0, // The offset of the polynomial kernel. [optional] default : 0.0.
		"sigma" : 1.0, // The sigma parameter of the gaussian kernel. [optional] default 1.0. 
		"a" : 0.5, // Sparse Passive Aggressive parameter a.
		"b" : 40, // Sparse Passive Aggressive parameter b.
		"maxSVs" : 500, // Maximum number of support vectors.
		"seed" : -1 // Give any non negative value for random reproducibility and any negative value for "completely random results".
    },
	
	"Parameters_Passive_Aggressive_Regressor" : {
		"encoding" : "UTF-8",
		"regularization" : "l2", // The regularization method. ('none', 'l1', 'l2')
		"C" : 0.001, // Regularization/Aggressiveness parameter for training. Default: 0.01
		"test_size" : 0.2, // Size of test dataset.
		"epochs" : 1, // Number of passes over the data.
		"epsilon" : 1e-5 // Regression loss insensitivity 
    },

	"NN_Classifier" : {
		"encoding" : "UTF-8",
		"Size_of_input_layer" : 100, // Size of input layer.
		"Number_of_hidden_layers" : 1, // The number of hidden layers.
		"hidden1" : 200, // Number of neurons in hidden layer 1.
		"hidden1_Activation" : "relu", // Activation function for hidden layer 1.
		"parameter_initialization" : "asdf", // Initialation technique for net parameters.
		"stepSize" : 0.001, // Learning rate of the optimizer.
		"batchSize" : 50, // The size of the batch that is to be fed to the Neural Network.  50
		"beta1" : 0.9, // The beta1 parameter of the Adam optimizer.
		"beta2" : 0.999, // The beta2 parameter of the Adam optimizer.
		"eps" : 1e-8, // Epsilon of the optimizer.
		"maxIterations" : 100, // Maximum iterations of the optimizer.   
		"tolerance" : 1e-5 // Tolerance of the optimizer.
	},
	
	"CNN_Classifier" : {
		"encoding" : "UTF-8",
		"stepSize" : 0.0001, // Learning rate of the optimizer.
		"batchSize" : 64, // The size of the batch that is to be fed to the Neural Network.  50
		"beta1" : 0.9, // The beta1 parameter of the Adam optimizer.
		"beta2" : 0.999, // The beta2 parameter of the Adam optimizer.
		"eps" : 1e-8, // Epsilon of the optimizer.
		"maxIterations" : 640, // Maximum iterations of the optimizer.   
		"tolerance" : 1e-5 // Tolerance of the optimizer.
	},
	
	"NN1_Classifier" : {
		"encoding" : "UTF-8",
		"Size_of_input_layer" : 18, // Size of input layer.
		"Number_of_hidden_layers" : 4, // The number of hidden layers.
		"hidden1" : 300, // Number of neurons in hidden layer 1.
		"hidden1_Activation" : "tanh", // Activation function for hidden layer 1.
		"hidden2" : 300, // Number of neurons in hidden layer 2.
		"hidden2_Activation" : "tanh", // Activation function for hidden layer 2.
		"hidden3" : 300, // Number of neurons in hidden layer 3.
		"hidden3_Activation" : "tanh", // Activation function for hidden layer 3.
		"hidden4" : 300, // Number of neurons in hidden layer 4.
		"hidden4_Activation" : "tanh", // Activation function for hidden layer 4.
		"parameter_initialization" : "asdf", // Initialation technique for net parameters.
		"stepSize" : 0.05, // Learning rate of the optimizer.
		"batchSize" : 100, // The size of the batch that is to be fed to the Neural Network.  50
		"beta1" : 0.9, // The beta1 parameter of the Adam optimizer.
		"beta2" : 0.999, // The beta2 parameter of the Adam optimizer.
		"eps" : 1e-8, // Epsilon of the optimizer.
		"maxIterations" : 1000, // Maximum iterations of the optimizer.   100
		"tolerance" : 1e-5, // Tolerance of the optimizer.
		"trsmt_mv_avrgs" : false
	},
	
	"NN_Regressor" : {
		"encoding" : "UTF-8",
		"Size_of_input_layer" : 100, // Size of input layer.
		"Number_of_hidden_layers" : 1, // The number of hidden layers.
		"hidden1" : 200, // Number of neurons in hidden layer 1.
		"hidden1_Activation" : "logistic", // Activation function for hidden layer 1.
		"parameter_initialization" : "asdf", // Initialation technique for net parameters.
		"stepSize" : 0.001, // Learning rate of the optimizer.
		"batchSize" : 1, // The size of the batch that is to be fed to the Neural Network.
		"beta1" : 0.9, // The beta1 parameter of the Adam optimizer.
		"beta2" : 0.999, // The beta2 parameter of the Adam optimizer.
		"eps" : 1e-8, // Epsilon of the optimizer.
		"maxIterations" : 1, // Maximum iterations of the optimizer.
		"tolerance" : 1e-8 // Tolerance of the optimizer.
	},

	"ELM" : {
		"encoding" : "UTF-8",
		"batch_size" : 128,
		"experiment" : 4,
		"neurons" : 250
	},

	"experimental_data" : {
		"encoding" : "UTF-8",
		"file_name" : "Experimental_Datasets.h5", // The name of the hdf5 file.
		"experiment" : "exp3"
	},

	"exp1" : {
		"train_dset_name" : "AMNIST",
		"test_dset_name" : "MNIST_Test"
	},

	"exp2" : {
		"train_dset_name" : "AMNIST",
		"test_dset_name" : "MNIST_Test",
		"train_dset_name_2" : "NAMNIST",
		"test_dset_name_2" : "NMNIST_Test"
	},

	"exp3" : {
		"train_dset_name" : "C1_Train",
		"test_dset_name" : "C1_Test",
		"train_dset_name_2" : "AMNIST",
		"test_dset_name_2" : "MNIST_Test"
	},

	"exp4" : {
		"train_dset_name" : "C1_Train",
		"test_dset_name" : "C1_Test",
		"train_dset_name_2" : "C2_Train",
		"test_dset_name_2" : "C2_Test"
	},

	"exp5" : {
		"train_dset_name" : "C2_Train",
		"test_dset_name" : "C2_Test",
		"train_dset_name_2" : "AMNIST",
		"test_dset_name_2" : "MNIST_Test"
	},

	"exp6" : {
		"train_dset_name" : "C2_Train",
		"test_dset_name" : "C2_Test",
		"train_dset_name_2" : "C1_Train",
		"test_dset_name_2" : "C2_Test"
	}

}
